{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec64ff2-bdfb-42e2-8951-9973f55c6f77",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"6\"><b>Ensemble Methods</font>\n",
    "<p><font color=\"Yellow\" size=\"5\"><b>1_BalancedRandomForestClassifier</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e63d8-cb82-420e-b907-60215252f4cd",
   "metadata": {},
   "source": [
    "The BalancedRandomForestClassifier is a classifier from the imbalanced-learn library that is specifically designed to handle imbalanced datasets. It is an extension of the Random Forest classifier, but with the added feature of balancing the class distribution within each decision tree during the training process. This is achieved by randomly under-sampling the majority class before each decision tree is built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33474da7-ee4c-4ed8-b452-a6984aedba1b",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>How It Works:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Random Forest Algorithm:</font> Like a standard Random Forest, the BalancedRandomForestClassifier builds multiple decision trees using a bagging approach. Each tree is trained on a random subset of the data.</li>\n",
    "    <li><font color=\"orange\">Class Balancing:</font> During the training of each individual tree, the majority class is under-sampled to match the size of the minority class, ensuring that each tree is trained on a balanced dataset. This prevents the model from being biased towards the majority class.</li>\n",
    "    <li><font color=\"orange\">Ensemble Learning:</font> Once all the trees are trained, their predictions are aggregated (using a majority vote or average) to make the final prediction. This results in a robust model that performs well on imbalanced datasets.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43f50e0-cc59-4394-9c48-99219d5e39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before BalancedRandomForestClassifier: Counter({0: 898, 1: 102})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\envs\\mydl\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\root\\anaconda3\\envs\\mydl\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\root\\anaconda3\\envs\\mydl\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution AFTER BalancedRandomForestClassifier: Counter({0: 898, 1: 102})\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       275\n",
      "           1       0.47      0.88      0.61        25\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.73      0.89      0.78       300\n",
      "weighted avg       0.94      0.91      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, \n",
    "                            n_redundant=10, n_classes=2, weights=[0.9, 0.1], \n",
    "                            random_state=42)\n",
    "\n",
    "# Step 2: Check the class distribution before applying BalancedRandomForestClassifier\n",
    "print(\"Class distribution before BalancedRandomForestClassifier:\", Counter(y))\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train the BalancedRandomForestClassifier\n",
    "clf = BalancedRandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution AFTER BalancedRandomForestClassifier:\", Counter(y))\n",
    "# Step 5: Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the classifier\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fad45f-a91f-450f-ae17-36de662da47b",
   "metadata": {},
   "source": [
    "<font color=\"sky blue\" size=4>Note:</font><b>\n",
    "The class distribution after using the BalancedRandomForestClassifier doesn't change in the sense of resampling the entire dataset. However, the classifier internally balances each individual decision tree during training by under-sampling the majority class to match the size of the minority class within each tree, which helps to address the class imbalance problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09324613-b73b-42ef-9c44-d1818bc3582f",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>Advantages of BalancedRandomForestClassifier:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Prevents Overfitting on Majority Class:</font> By under-sampling the majority class for each tree, the model prevents the majority class from overwhelming the decision trees.</li>\n",
    "    <li><font color=\"orange\">Better Performance on Imbalanced Datasets:</font> It improves the classification performance, especially for the minority class, by ensuring the model does not become biased towards the majority class.</li>\n",
    "    <li><font color=\"orange\">Ensemble Method:</font> Like other ensemble methods, Random Forest is more robust and performs better compared to a single classifier.</li></ol>\n",
    "\n",
    "<font color=\"pink\" size=4>Limitations:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Loss of Majority Class Information:</font> By under-sampling the majority class for each tree, the classifier may lose important information from the majority class, especially in cases where the majority class has a large amount of data.</li>\n",
    "    <li><font color=\"orange\">Computational Complexity:</font> Random forests are computationally expensive, and balancing each tree further adds to the complexity.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510aa8c-aceb-4516-8d4e-9fa4eced5d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
