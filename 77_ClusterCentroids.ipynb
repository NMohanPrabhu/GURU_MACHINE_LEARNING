{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e4518a-e711-4e6f-a658-d294da6900a5",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"6\">Undersampling Methods</font>\n",
    "<p><font color=\"yellow\" size=\"5\"><b>3_ClusterCentroids</b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141fbb71-3bd2-4578-b151-e19fa5dbc28c",
   "metadata": {},
   "source": [
    "ClusterCentroids is an under-sampling technique used to handle class imbalance in datasets. It works by identifying clusters of majority class samples and replacing them with centroids (the mean of the samples in the cluster). This technique aims to reduce the size of the majority class while preserving the overall structure of the data. By representing clusters of majority class samples with their centroids, it helps to maintain important characteristics of the majority class while reducing its number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6be46-b2b1-4dd6-8ac0-c88cc61684d7",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>How ClusterCentroids Works:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Clustering the Majority Class:</font>\n",
    "        The first step is to perform clustering (typically using KMeans) on the majority class samples. The goal is to group similar samples together into clusters.</li>\n",
    "   <li><font color=\"orange\">Generate Centroids:</font>\n",
    "        After clustering the majority class, the centroids of these clusters are calculated. A centroid represents the mean of all the samples in a cluster.</li>\n",
    "    <li><font color=\"orange\">Replace Majority Class Samples with Centroids:</font>\n",
    "        The majority class samples are then replaced with a smaller number of centroids. This reduces the number of majority class instances, while still preserving the essential characteristics of the data.</li>\n",
    "    <li><font color=\"orange\">Resampling:</font>\n",
    "        The resulting dataset has a reduced number of majority class samples, making the dataset more balanced. The minority class samples remain unchanged.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2133ddbe-59ef-4470-aada-f012a11e023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before ClusterCentroids: Counter({0: 898, 1: 102})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\envs\\mydl\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after ClusterCentroids: Counter({0: 102, 1: 102})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        32\n",
      "           1       0.93      0.87      0.90        30\n",
      "\n",
      "    accuracy                           0.90        62\n",
      "   macro avg       0.91      0.90      0.90        62\n",
      "weighted avg       0.90      0.90      0.90        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, \n",
    "                            n_redundant=10, n_classes=2, weights=[0.9, 0.1], \n",
    "                            random_state=42)\n",
    "\n",
    "# Step 2: Check the class distribution before applying ClusterCentroids\n",
    "print(\"Class distribution before ClusterCentroids:\", Counter(y))\n",
    "\n",
    "# Step 3: Apply ClusterCentroids to balance the dataset\n",
    "cluster_centroids = ClusterCentroids(random_state=42)\n",
    "X_resampled, y_resampled = cluster_centroids.fit_resample(X, y)\n",
    "\n",
    "# Step 4: Check the class distribution after applying ClusterCentroids\n",
    "print(\"Class distribution after ClusterCentroids:\", Counter(y_resampled))\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier (RandomForest) on the resampled data\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd4ef3-4baa-4b42-883e-a4786bd7285e",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>Advantages of ClusterCentroids:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Preserves Data Structure:</font> By using centroids of clusters, this technique retains the important patterns of the majority class while reducing its size.</li>\n",
    "    <li><font color=\"orange\">Improves Class Separation:</font> By reducing the majority class and removing redundant samples, it helps to improve the separability between the classes.</li>\n",
    "    <li><font color=\"orange\">No Synthetic Data Generation:</font> Unlike SMOTE, ClusterCentroids does not generate synthetic data, which can avoid potential overfitting that may arise from creating too many new synthetic samples.</li></ol>\n",
    "\n",
    "<font color=\"pink\" size=4>Drawbacks of ClusterCentroids:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Loss of Information:</font> By reducing the number of majority class samples, some information from the majority class may be lost. The centroids may not capture all the nuances of the original data.</li>\n",
    "    <li><font color=\"orange\">Cluster Dependency:</font> The effectiveness of the technique depends on the quality of the clustering. If clustering does not produce meaningful clusters, the resulting centroids may not be representative of the majority class.</li>\n",
    "    <li><font color=\"orange\">Not Suitable for All Types of Data:</font> ClusterCentroids is particularly useful when the data has well-defined clusters. It may not perform well if the data does not exhibit clear clustering structures.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53767d16-cb56-4e1e-9ac2-4afbe227e473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
