{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f000ab23-ba30-4ce1-a43b-a97a4aec6b84",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"6\">Techniques for handling imbalanced datasets</font>\n",
    "<P><font color=\"yELLOW\" size=\"5\"><B>3_BorderlineSMOTE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3399b954-e884-4865-af74-1fbbf91f6ddd",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>BorderlineSMOTE</font>\n",
    "\n",
    "BorderlineSMOTE is a variant of the original SMOTE (Synthetic Minority Over-sampling Technique). It specifically focuses on generating synthetic samples near the decision boundary (i.e., borderline samples) between the majority and minority classes. The idea behind BorderlineSMOTE is to focus on the most difficult samples to classify, which are the ones lying near the decision boundary. This can help improve the classifier's ability to distinguish between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dc10f-4650-4c7d-9f96-a9e9e4f4461c",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>How BorderlineSMOTE Works:</font>\n",
    "<ol>\n",
    "     <li><font color=\"orange\">Borderline Samples:</font> BorderlineSMOTE identifies the samples from the minority class that are near the decision boundary between the majority and minority classes.</li>\n",
    "     <li><font color=\"orange\">Synthetic Samples Generation:</font> It generates synthetic samples by creating new samples from the minority class only near the decision boundary, similar to SMOTE, but focusing on these borderline samples.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a8361b-035c-4eb8-b00b-c0e7c215af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before BorderlineSMOTE: Counter({0: 898, 1: 102})\n",
      "Class distribution after BorderlineSMOTE: Counter({0: 898, 1: 898})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       265\n",
      "           1       0.95      0.98      0.97       274\n",
      "\n",
      "    accuracy                           0.96       539\n",
      "   macro avg       0.97      0.96      0.96       539\n",
      "weighted avg       0.97      0.96      0.96       539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, \n",
    "                            n_redundant=10, n_classes=2, weights=[0.9, 0.1], \n",
    "                            random_state=42)\n",
    "\n",
    "# Step 2: Check the class distribution before applying BorderlineSMOTE\n",
    "print(\"Class distribution before BorderlineSMOTE:\", Counter(y))\n",
    "\n",
    "# Step 3: Apply BorderlineSMOTE to oversample the minority class\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_resampled, y_resampled = borderline_smote.fit_resample(X, y)\n",
    "\n",
    "# Step 4: Check the class distribution after applying BorderlineSMOTE\n",
    "print(\"Class distribution after BorderlineSMOTE:\", Counter(y_resampled))\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, \n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier (RandomForest) on the resampled data\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a4b28-7ff1-44c2-bcc9-d55aa946585e",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>Advantages of BorderlineSMOTE:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Focuses on Borderline Samples:</font> BorderlineSMOTE focuses on generating synthetic samples for those minority class samples that are near the decision boundary, which are typically harder to classify.</li>\n",
    "    <li><font color=\"orange\">Improved Classifier Performance:</font> This technique can improve the performance of classifiers by making them better at distinguishing between the classes, especially when class overlap is high.</li>\n",
    "    <li><font color=\"orange\">Better for Noisy Data:</font> By focusing on the most difficult-to-classify minority samples, it can lead to a better classification decision boundary.</li></ol>\n",
    "\n",
    "<font color=\"pink\" size=4>Drawbacks of BorderlineSMOTE:</font>\n",
    "<ol>\n",
    "    <li><font color=\"orange\">Noise Sensitivity:</font> If there are noisy data points near the decision boundary, BorderlineSMOTE may amplify this noise, leading to overfitting.</li>\n",
    "    <li><font color=\"orange\">Computational Complexity:</font> Like SMOTE, BorderlineSMOTE can be computationally expensive, especially for large datasets.</li>\n",
    "    <li><font color=\"orange\">Overfitting Risk:</font> If the synthetic samples are too close to existing samples, overfitting can occur, especially when training more complex models.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e50789-e83a-48ea-806d-01132e2e41da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
