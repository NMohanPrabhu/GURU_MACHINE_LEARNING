{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ce2e35-228d-4b1f-8e0a-9257a329e01c",
   "metadata": {},
   "source": [
    "<font color=\"red\" size=\"6\">Ensemble methods</font>\n",
    "<p> <font color=\"Yellow\" size=\"5\"><b>7_Voting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f78d3-839f-4691-9f12-a2ca72d0dbcb",
   "metadata": {},
   "source": [
    "Voting Classifier is another ensemble learning technique that combines the predictions of multiple models to improve the overall performance. The idea behind a voting classifier is that by aggregating the predictions of several base models, the final prediction is less likely to overfit or be biased by the weaknesses of any single model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7d5aa-9b82-4661-ac7b-77b4af9d155d",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>Types of Voting Classifiers:</font>\n",
    "<ol>\n",
    "     <li><font color=\"orange\">Hard Voting (Majority Voting):</font>\n",
    "        Each base model makes a prediction, and the final prediction is the one that gets the majority vote. In the case of a tie, the class with the lower index is selected.</li>\n",
    "     <li><font color=\"orange\">Soft Voting (Average of Probabilities):</font>\n",
    "        Instead of making hard predictions (class labels), each base model outputs probabilities for each class. The final prediction is based on the average (or sum) of these probabilities, and the class with the highest average probability is selected.\n",
    "        Soft voting is generally preferred when the base classifiers output probabilities, as it often leads to better performance.</li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab839d13-e73d-4357-bbc3-af16379ec819",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>Advantages of Voting:</font>\n",
    "<ol>\n",
    "     <li><font color=\"orange\">Improved Accuracy:</font> By combining multiple models, voting classifiers tend to perform better than individual models, especially when the models are diverse.</li>\n",
    "     <li><font color=\"orange\">Robustness:</font> Voting classifiers are less likely to overfit compared to individual models, especially if the models are of different types (e.g., a decision tree, logistic regression, and a KNN).</li>\n",
    "     <li><font color=\"orange\">Simplicity:</font> It is a simple and easy-to-implement technique.</li></ol>\n",
    "\n",
    "<font color=\"pink\" size=4>Disadvantages of Voting:</font>\n",
    "<ol>\n",
    "     <li><font color=\"orange\">Computational Cost:</font> Since multiple models are being trained and predictions are being made, voting classifiers can be more computationally expensive.</li>\n",
    "     <li><font color=\"orange\">No Guarantee of Improvement:</font> If the base models are similar or poorly chosen, the voting classifier may not outperform a single well-tuned model.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e613b28-6aed-40b2-aa53-d08f65c0f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a76ee84-5a5b-4d22-992a-58f506706680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Wine dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21249b06-853d-4107-933f-ac52b2d45be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define base models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03321f82-e25d-4b4a-b10b-49df7a1e6080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create hard voting classifier (majority voting)\n",
    "voting_hard = VotingClassifier(estimators=[\n",
    "    ('lr', log_reg),\n",
    "    ('knn', knn),\n",
    "    ('dt', dt)\n",
    "], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83df8ea-6c51-4751-b080-8c73563e3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create soft voting classifier (average of probabilities)\n",
    "voting_soft = VotingClassifier(estimators=[\n",
    "    ('lr', log_reg),\n",
    "    ('knn', knn),\n",
    "    ('dt', dt)\n",
    "], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7b9b75-71d5-4a07-b17a-ce5a0be402cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\envs\\mydl\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;knn&#x27;, KNeighborsClassifier()),\n",
       "                             (&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;knn&#x27;, KNeighborsClassifier()),\n",
       "                             (&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(max_iter=1000)),\n",
       "                             ('knn', KNeighborsClassifier()),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Train the hard voting model\n",
    "voting_hard.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23dfa8b-662e-45eb-8048-892fb826fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\envs\\mydl\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;knn&#x27;, KNeighborsClassifier()),\n",
       "                             (&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;knn&#x27;, KNeighborsClassifier()),\n",
       "                             (&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(max_iter=1000)),\n",
       "                             ('knn', KNeighborsClassifier()),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Train the soft voting model\n",
    "voting_soft.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7aacf12-3a96-41ee-82d4-6ea15cec4c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Make predictions using the hard voting model\n",
    "y_pred_hard = voting_hard.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3619c9ad-0313-490a-b63f-38aa2a154213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Make predictions using the soft voting model\n",
    "y_pred_soft = voting_soft.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d9ece4-4853-4185-9801-f208a6dac16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluate the hard voting model\n",
    "accuracy_hard = accuracy_score(y_test, y_pred_hard)\n",
    "print(f\"Hard Voting Accuracy: {accuracy_hard:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e58b4e78-62b2-4e4f-b9d9-3eeb6f757288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hard Voting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the classification report and confusion matrix for hard voting\n",
    "print(\"\\nHard Voting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b1fc17e-7971-4f92-87e0-9fb3203bf52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hard Voting Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHard Voting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7792524-372e-4b3c-b3f5-862780cf8fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Soft Voting Accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "# 11. Evaluate the soft voting model\n",
    "accuracy_soft = accuracy_score(y_test, y_pred_soft)\n",
    "print(f\"\\nSoft Voting Accuracy: {accuracy_soft:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2666e178-0b8d-4bfa-a97b-5fee2b615188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Soft Voting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the classification report and confusion matrix for soft voting\n",
    "print(\"\\nSoft Voting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fbe2e0a-56ab-44f1-9456-e4e71291ea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Soft Voting Confusion Matrix:\n",
      "[[18  1  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSoft Voting Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9de66e-1daa-4e3a-9121-a1bcce1f4cee",
   "metadata": {},
   "source": [
    "<font color=\"pink\" size=4>Key Hyperparameters of VotingClassifier:</font>\n",
    "<ol>\n",
    "     <li><font color=\"orange\">estimators:</font> A list of tuples containing the name and model of each base model.</li>\n",
    "     <li><font color=\"orange\">voting:</font> Determines the voting method:\n",
    "       <ol><li><font color=\"violet\"> 'hard':</font> Majority voting.</li>\n",
    "        <li><font color=\"violet\">'soft':</font> Averaging of predicted probabilities.</li></ol></li>\n",
    "     <li><font color=\"orange\">weights:</font> The weight of each model in the ensemble. This can be set if you want to give more importance to some base models than others.</li>\n",
    "     <li><font color=\"orange\">n_jobs:</font> Number of jobs to run in parallel. -1 uses all available cores.</li>\n",
    "     <li><font color=\"orange\">verbose:</font> Controls the verbosity of the training process.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45504b6-2df3-4c35-a894-05cead46e97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
